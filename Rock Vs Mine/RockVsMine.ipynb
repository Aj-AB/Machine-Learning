{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Rock vs Mine Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the dataset to a pandas Dataframe\n",
    "dataset = pd.read_csv('/media/aj/F/Rock Vs Mine/sonar.all-data.csv', header=None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape # check rows an column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Train data \n",
      " 0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "56    0\n",
      "57    0\n",
      "58    0\n",
      "59    0\n",
      "60    0\n",
      "Length: 61, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Missing values in Train data','\\n',dataset.isnull().sum()) # checking the null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # Visualizing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.034989</td>\n",
       "      <td>0.045544</td>\n",
       "      <td>0.050720</td>\n",
       "      <td>0.064768</td>\n",
       "      <td>0.086715</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>0.128359</td>\n",
       "      <td>0.149832</td>\n",
       "      <td>0.213492</td>\n",
       "      <td>0.251022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>0.006930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.022498</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.041447</td>\n",
       "      <td>0.062028</td>\n",
       "      <td>0.096224</td>\n",
       "      <td>0.114180</td>\n",
       "      <td>0.117596</td>\n",
       "      <td>0.137392</td>\n",
       "      <td>0.159325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012311</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>0.008567</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.006024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "60                                                                         \n",
       "M   0.034989  0.045544  0.050720  0.064768  0.086715  0.111864  0.128359   \n",
       "R   0.022498  0.030303  0.035951  0.041447  0.062028  0.096224  0.114180   \n",
       "\n",
       "          7         8         9   ...        50        51        52        53  \\\n",
       "60                                ...                                           \n",
       "M   0.149832  0.213492  0.251022  ...  0.019352  0.016014  0.011643  0.012185   \n",
       "R   0.117596  0.137392  0.159325  ...  0.012311  0.010453  0.009640  0.009518   \n",
       "\n",
       "          54        55        56        57        58        59  \n",
       "60                                                              \n",
       "M   0.009923  0.008914  0.007825  0.009060  0.008695  0.006930  \n",
       "R   0.008567  0.007430  0.007814  0.006677  0.007078  0.006024  \n",
       "\n",
       "[2 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby(60).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[60] = dataset[60].map({'M':1,'R':0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column 60\n",
    "dataset.rename(columns={60 : 'Target'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:,:-1].values # Separating label and feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02  , 0.0371, 0.0428, ..., 0.0084, 0.009 , 0.0032],\n",
       "       [0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
       "       [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
       "       ...,\n",
       "       [0.0522, 0.0437, 0.018 , ..., 0.0138, 0.0077, 0.0031],\n",
       "       [0.0303, 0.0353, 0.049 , ..., 0.0079, 0.0036, 0.0048],\n",
       "       [0.026 , 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dataset.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "203    1\n",
       "204    1\n",
       "205    1\n",
       "206    1\n",
       "207    1\n",
       "Name: Target, Length: 208, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aj/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as  sns\n",
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.countplot(x='Target', data=dataset, palette='autumn')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "Mine = dataset.Target[dataset.Target == 'M'].count()\n",
    "Rock = dataset.Target[dataset.Target == 'R'].count()\n",
    "plt.title(\"Target\", {\"fontsize\":20})\n",
    "plt.pie([Mine, Rock], labels=['Mine', 'Rock'], explode=[0.01,0.01], autopct='%.2f%%', colors=['yellow', 'lightgreen'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Model prediction\n",
    "Algorithms used:\n",
    "\n",
    "Logistic Regression\n",
    "Decision Tree Classifier\n",
    "Random Forest Classifier\n",
    "GBM Classifier\n",
    "XGBoost Classifier\n",
    "Light GBM classifier\n",
    "Catboost classifier\n",
    "KNN Classifier\n",
    "Support Vector Classifier (Linear SVM, Kernal SVM)\n",
    "Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV, KFold, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score,roc_auc_score,confusion_matrix\n",
    "from sklearn import model_selection\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=9\n",
    "#preparing models\n",
    "models=[]\n",
    "\n",
    "models.append(('Logistic Regression',LogisticRegression()))\n",
    "models.append(('Decision Tree Classifier',DecisionTreeClassifier()))\n",
    "models.append(('Random Forest Classifier',RandomForestClassifier()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('XGBoost Classifier',XGBClassifier()))\n",
    "models.append(('Light GBM classifier',LGBMClassifier()))\n",
    "models.append(('KNN Classifier',KNeighborsClassifier()))\n",
    "models.append(('Support Vector Classifier',SVC()))\n",
    "models.append(('Naive Bayes Classifier',GaussianNB()))\n",
    "models.append\n",
    "\n",
    "result=[]\n",
    "names=[]\n",
    "scoring='accuracy'\n",
    "for name,model in models:\n",
    "    kfold=KFold(n_splits=10)\n",
    "    cv_results=cross_val_score(model,X_train,y_train,cv=kfold,scoring=scoring)\n",
    "    result.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipelines = []\n",
    "pipelines.append(('LR', Pipeline([('Scaler', StandardScaler()), ('LR', LogisticRegression())])))\n",
    "pipelines.append(('LDA', Pipeline([('Scaler', StandardScaler()), ('LDA', LinearDiscriminantAnalysis())])))\n",
    "pipelines.append(('KNN', Pipeline([('Scaler', StandardScaler()), ('KNN', KNeighborsClassifier())])))\n",
    "pipelines.append(('DTC', Pipeline([('Scaler', StandardScaler()), ('CART', DecisionTreeClassifier())])))\n",
    "pipelines.append(('NB', Pipeline([('Scaler', StandardScaler()), ('NB', GaussianNB())])))\n",
    "pipelines.append(('XGB', Pipeline([('Scaler', StandardScaler()), ('XGB', XGBClassifier())])))\n",
    "pipelines.append(('LGBM', Pipeline([('Scaler', StandardScaler()), ('GMB', LGBMClassifier())])))\n",
    "pipelines.append(('SVM', Pipeline([('Scaler', StandardScaler()), ('SVM', SVC())])))\n",
    "pipelines.append(('RFC', Pipeline([('Scaler', StandardScaler()), ('RFC', RandomForestClassifier())])))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Scaled Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN algorithm tuning\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaled_X = scaler.transform(X_train)\n",
    "neighbors = [1,3,5,7,9,11,13,15,17,19,21]\n",
    "param_grid = dict(n_neighbors=neighbors)\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=10)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaled_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.867279 using {'n_neighbors': 1}\n",
      "#1 0.867279 (0.073941) with: {'n_neighbors': 1}\n",
      "#2 0.819485 (0.079099) with: {'n_neighbors': 3}\n",
      "#3 0.795221 (0.087945) with: {'n_neighbors': 5}\n",
      "#4 0.770956 (0.082636) with: {'n_neighbors': 7}\n",
      "#5 0.747426 (0.077242) with: {'n_neighbors': 9}\n",
      "#7 0.710662 (0.108541) with: {'n_neighbors': 11}\n",
      "#11 0.698529 (0.116179) with: {'n_neighbors': 13}\n",
      "#10 0.703676 (0.143460) with: {'n_neighbors': 15}\n",
      "#6 0.716176 (0.100762) with: {'n_neighbors': 17}\n",
      "#7 0.710662 (0.118848) with: {'n_neighbors': 19}\n",
      "#9 0.704044 (0.106354) with: {'n_neighbors': 21}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "ranks = grid_result.cv_results_['rank_test_score']\n",
    "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
    "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # XGB: 0.813235 (0.093657) algorithm tuning\n",
    "\n",
    "param_XGB = {'n_estimators': [50, 100, 200],'learning_rate': [0.01,0.1,1]}\n",
    "xgb_model = XGBClassifier()\n",
    "kfold = KFold(n_splits=10)\n",
    "grid = GridSearchCV(estimator=xgb_model, param_grid=param_XGB, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaled_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best : 0.819485 using {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "#8 0.741544 (0.083869) with: {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "#9 0.741176 (0.075385) with: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "#7 0.759191 (0.091650) with: {'learning_rate': 0.01, 'n_estimators': 200}\n",
      "#6 0.801471 (0.095305) with: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "#5 0.813235 (0.093657) with: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "#1 0.819485 (0.071070) with: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "#2 0.813971 (0.093692) with: {'learning_rate': 1, 'n_estimators': 50}\n",
      "#2 0.813971 (0.093692) with: {'learning_rate': 1, 'n_estimators': 100}\n",
      "#2 0.813971 (0.093692) with: {'learning_rate': 1, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(' Best : %f using %s' % (grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "ranks = grid_result.cv_results_['rank_test_score']\n",
    "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
    "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM: 0.843382 (0.082129) algorithm tuning\n",
    "param_LGBM = {'n_estimators':range(100,201,25),'learning_rate':[0.01,0.1,1],\n",
    "             'max_depth':[7,8,9]}\n",
    "lgbm_model = LGBMClassifier()\n",
    "kfold = KFold(n_splits=10)\n",
    "grid = GridSearchCV(estimator=lgbm_model, param_grid=param_LGBM, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaled_X, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Best : %f using %s' % (grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "ranks = grid_result.cv_results_['rank_test_score']\n",
    "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
    "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM: 0.806985 (0.052207) hyper-tuning\n",
    "\n",
    "para_SVM= {'C': [1,5,10],'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'degree':[1,2,3,4]}\n",
    "SVM_model=SVC()\n",
    "kfold=KFold(n_splits=10)\n",
    "grid=GridSearchCV(estimator=SVM_model,param_grid=para_SVM,scoring=scoring, cv=kfold)\n",
    "grid_result=grid.fit(rescaled_X,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.879779 using {'C': 5, 'degree': 1, 'kernel': 'rbf'}\n",
      "#45 0.795588 (0.064819) with: {'depth': 8, 'iterations': 800, 'learning_rate': 1}\n"
     ]
    }
   ],
   "source": [
    "print('Best : %f using %s' % (grid_result.best_score_,grid_result.best_params_))\n",
    "means=grid_result.cv_results_['mean_test_score']\n",
    "stds=grid_result.cv_results_['std_test_score']\n",
    "params=grid_result.cv_results_['params']\n",
    "ranks=grid_result.cv_results_['rank_test_score']\n",
    "print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC: 0.837132 (0.038736) hyper-tuning\n",
    "\n",
    "para_rfc= {'n_estimators': [5,20,50,100],\n",
    "# Number of features to consider at every split\n",
    "'max_features': ['auto', 'sqrt'],\n",
    "# Maximum number of levels in tree\n",
    "'max_depth':[2,4],\n",
    "# Minimum number of samples required to split a node\n",
    "'min_samples_split': [2, 5],\n",
    "# Minimum number of samples required at each leaf node\n",
    "'min_samples_leaf' : [1, 2],\n",
    "# Method of selecting samples for training each tree\n",
    "'bootstrap':[True, False]}\n",
    "RFC_model=RandomForestClassifier()\n",
    "kfold=KFold(n_splits=10)\n",
    "grid=GridSearchCV(estimator=RFC_model,param_grid=para_rfc,scoring=scoring, cv=kfold)\n",
    "grid_result=grid.fit(rescaled_X,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.848897 using {'bootstrap': False, 'max_depth': 4, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "#45 0.795588 (0.064819) with: {'depth': 8, 'iterations': 800, 'learning_rate': 1}\n"
     ]
    }
   ],
   "source": [
    "print('Best : %f using %s' % (grid_result.best_score_,grid_result.best_params_))\n",
    "means=grid_result.cv_results_['mean_test_score']\n",
    "stds=grid_result.cv_results_['std_test_score']\n",
    "params=grid_result.cv_results_['params']\n",
    "ranks=grid_result.cv_results_['rank_test_score']\n",
    "print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = SVC(C=5) # rbf is default kernel\n",
    "model.fit(rescaledX, y_train.replace({1:'M',0:'R'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285714285714286\n",
      "[[21  0]\n",
      " [ 3 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           M       0.88      1.00      0.93        21\n",
      "           R       1.00      0.86      0.92        21\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.94      0.93      0.93        42\n",
      "weighted avg       0.94      0.93      0.93        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledValidationX = scaler.transform(X_test)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(accuracy_score(y_test.replace({1:'M',0:'R'}), predictions))\n",
    "print(confusion_matrix(y_test.replace({1:'M',0:'R'}), predictions))\n",
    "print(classification_report(y_test.replace({1:'M',0:'R'}), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'R', 'M', 'R', 'M', 'R', 'M', 'M', 'R', 'M', 'R', 'M', 'R',\n",
       "       'M', 'R', 'R', 'M', 'R', 'R', 'R', 'M', 'R', 'M', 'R', 'R', 'M',\n",
       "       'M', 'M', 'M', 'M', 'R', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'R'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12     R\n",
       "80     R\n",
       "33     R\n",
       "5      R\n",
       "187    M\n",
       "83     R\n",
       "116    M\n",
       "122    M\n",
       "90     R\n",
       "154    M\n",
       "45     R\n",
       "156    M\n",
       "52     R\n",
       "189    M\n",
       "96     R\n",
       "86     R\n",
       "204    M\n",
       "37     R\n",
       "66     R\n",
       "18     R\n",
       "170    M\n",
       "15     R\n",
       "7      R\n",
       "55     R\n",
       "92     R\n",
       "134    M\n",
       "125    M\n",
       "124    M\n",
       "158    M\n",
       "184    M\n",
       "75     R\n",
       "149    M\n",
       "138    M\n",
       "71     R\n",
       "186    M\n",
       "145    M\n",
       "176    M\n",
       "118    M\n",
       "16     R\n",
       "135    M\n",
       "190    M\n",
       "22     R\n",
       "Name: Target, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.replace({1:'M',0:'R'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
